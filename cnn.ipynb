{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ManeuverDetectionDataset import ManeuverDetectionDataset, IrregularDataset, SlidingWindowDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_l_out(l_in, kernel_size, padding=0, dilation=1, stride=1):\n",
    "    return np.floor((l_in + 2 * padding - dilation * (kernel_size - 1) -1)/stride + 1)\n",
    "\n",
    "class ConvBlock1d(torch.nn.Module):\n",
    "    def __init__(self, conv_kwargs, pool_kwargs, dropout_rate) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        self.conv = torch.nn.Conv1d(**conv_kwargs)\n",
    "        self.activation_fn = torch.nn.ReLU()\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html\n",
    "        self.pooling = torch.nn.MaxPool1d(**pool_kwargs)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation_fn(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Cnn1d(torch.nn.Module):\n",
    "    def __init__(self, block_kwargs_list, linear_kwargs) -> None: # use_dv_head=False, use_date_head=False\n",
    "        super().__init__()\n",
    "        self.block_kwargs_list = block_kwargs_list\n",
    "        ll = []\n",
    "        for block_kwargs in block_kwargs_list:\n",
    "            ll.append(ConvBlock1d(**block_kwargs))\n",
    "\n",
    "        self.convnet = torch.nn.Sequential(*ll)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.fcnn = torch.nn.Linear(**linear_kwargs)\n",
    "        self.activation_fn = torch.nn.ReLU()\n",
    "\n",
    "        self.classification_head = torch.nn.Sequential(*[\n",
    "            torch.nn.Linear(linear_kwargs['out_features'], 2),\n",
    "            torch.nn.Softmax(dim=-1)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # main model\n",
    "        x = self.convnet(x)\n",
    "        x = torch.flatten(x, start_dim=1) # size : batch size x length\n",
    "        x = self.fcnn(x)\n",
    "        x = self.activation_fn(x)\n",
    "\n",
    "        # classification head\n",
    "        c = self.classification_head(x)\n",
    "        return c\n",
    "    \n",
    "    def predict(self, x, return_embedding=False):\n",
    "        self.eval()\n",
    "        # main model\n",
    "        x = self.convnet(x)\n",
    "        x = torch.flatten(x, start_dim=1) # size : batch size x length\n",
    "        x = self.fcnn(x)\n",
    "        x = self.activation_fn(x)\n",
    "\n",
    "        # classification head\n",
    "        c = self.classification_head(x)\n",
    "        if(return_embedding):\n",
    "            return c, x\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TorchTrainer:\n",
    "    def __init__(self, model, lr, verbose=True, weight=None, index_y=0, loss_function=\"CrossEntropyLoss\") -> None:\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.weight = weight\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(self.device)\n",
    "        if(loss_function == 'CrossEntropyLoss'):\n",
    "            self.loss_function = torch.nn.CrossEntropyLoss(weight=self.weight) # torch.tensor([0.05, 0.95]))\n",
    "        elif(loss_function == \"L1Loss\"):\n",
    "            self.loss_function = torch.nn.L1Loss()\n",
    "        self.optimiser = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=0.9)\n",
    "        self.verbose = verbose\n",
    "        self.index_y = index_y\n",
    "        self.scheduler = torch.optim.lr_scheduler.CyclicLR(self.optimiser, base_lr=lr, max_lr=10 * lr)\n",
    "    \n",
    "    def train(self, train_loader, epochs):\n",
    "        train_loss_list = []\n",
    "        for epoch in tqdm(range(epochs), disable=not self.verbose):\n",
    "            train_loss = self.train_one_epoch(train_loader)\n",
    "            train_loss_list.append(train_loss)\n",
    "        return train_loss_list\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        loss_list = []\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(self.device)\n",
    "            y = tuple([y_.to(self.device) for y_ in y])\n",
    "            pred = self.model(x)\n",
    "            self.optimiser.zero_grad()\n",
    "            loss = self.loss_function(pred, y[self.index_y])\n",
    "            loss.backward()\n",
    "            self.optimiser.step()\n",
    "            loss_list.append(loss.detach().cpu().numpy())\n",
    "            self.scheduler.step()\n",
    "        return np.mean(loss_list)\n",
    "\n",
    "    def predict(self, test_loader, return_true=False):\n",
    "        self.model.eval()\n",
    "        c_pred_list = []\n",
    "        c_true_list = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(self.device)\n",
    "                y = tuple([y_.to(self.device) for y_ in y])\n",
    "                pred = self.model(x)\n",
    "                c_pred_list.append(pred)\n",
    "                # dv_pred_list.append(pred[1])\n",
    "                c_true_list.append(y[self.index_y])\n",
    "                # dv_true_list.append(y[1])\n",
    "        self.model.train()\n",
    "\n",
    "        pred_tuple = (torch.concatenate(c_pred_list, axis=0),)\n",
    "                # torch.concatenate(dv_pred_list, axis=0))        \n",
    "        if(return_true):\n",
    "            true_tuple = (torch.concatenate(c_true_list, axis=0),)\n",
    "                # torch.concatenate(dv_true_list, axis=0))\n",
    "            return true_tuple, pred_tuple\n",
    "        return pred_tuple\n",
    "\n",
    "#     def score(self, test_loader):\n",
    "#         true, pred = self.predict(test_loader, return_true=True)\n",
    "#         accuracy = get_accuracy(true.cpu().numpy(), pred.cpu().numpy())\n",
    "#         return accuracy\n",
    "\n",
    "# def get_accuracy(y_true, y_prob):\n",
    "#     assert (y_true.ndim == 1 and y_true.shape[0] == y_prob.shape[0])\n",
    "#     y_prob = np.argmax(y_prob, axis=-1)\n",
    "#     return sklearn.metrics.accuracy_score(y_true, y_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 :\n",
    "Detect which time series contain maneuvers.\n",
    "\n",
    "CNN to determine on full time series, not evenly spaced, if it contains a maneuver or not.\n",
    "\n",
    "Fixed size of the time series : 1000 (48h of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_kwargs_list_1000 = [\n",
    "    { # layer 1\n",
    "        'conv_kwargs': {\n",
    "            'in_channels': 3,\n",
    "            'out_channels': 6,\n",
    "            'kernel_size': 7,\n",
    "            'stride': 1,\n",
    "            'padding': 0,\n",
    "            'dilation': 1,\n",
    "            'groups': 1,\n",
    "            'bias': True,\n",
    "            'padding_mode': 'zeros'\n",
    "        },\n",
    "        'pool_kwargs': {\n",
    "            'kernel_size': 7,\n",
    "            'stride': None,\n",
    "            'padding': 0,\n",
    "            'dilation': 1\n",
    "        },\n",
    "        'dropout_rate': 0.3\n",
    "    },\n",
    "    { # layer 2\n",
    "        'conv_kwargs': {\n",
    "            'in_channels': 6,\n",
    "            'out_channels': 12,\n",
    "            'kernel_size': 7,\n",
    "            'stride': 1,\n",
    "            'padding': 0,\n",
    "            'dilation': 1,\n",
    "            'groups': 1,\n",
    "            'bias': True,\n",
    "            'padding_mode': 'zeros'\n",
    "        },\n",
    "        'pool_kwargs': {\n",
    "            'kernel_size': 7,\n",
    "            'stride': None,\n",
    "            'padding': 0,\n",
    "            'dilation': 1\n",
    "        },\n",
    "        'dropout_rate': 0.3\n",
    "    },\n",
    "    { # layer 3\n",
    "        'conv_kwargs': {\n",
    "            'in_channels': 12,\n",
    "            'out_channels':12,\n",
    "            'kernel_size': 7,\n",
    "            'stride': 1,\n",
    "            'padding': 0,\n",
    "            'dilation': 1,\n",
    "            'groups': 1,\n",
    "            'bias': True,\n",
    "            'padding_mode': 'zeros'\n",
    "        },\n",
    "        'pool_kwargs': {\n",
    "            'kernel_size': 5,\n",
    "            'stride': None,\n",
    "            'padding': 0,\n",
    "            'dilation': 1\n",
    "        },\n",
    "        'dropout_rate': 0.3\n",
    "    }\n",
    "]\n",
    "linear_kwargs_1000 = {\n",
    "    'in_features': 24,\n",
    "    'out_features': 10 # size of the projection space (dimension reduction)\n",
    "}\n",
    "\n",
    "conv_net_1000 = Cnn1d(block_kwargs_list_1000, linear_kwargs_1000).float()\n",
    "\n",
    "# test\n",
    "c = conv_net_1000(torch.zeros(4, 3, 1000).float())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**********TRAIN DATASET *********\n",
      "Validation/Train ratio: 0.1\n",
      "Samples filtered? NO\n",
      "Samples evenly spaced? False\n",
      "path: DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\n",
      "loading dataset. Ready in a minute!\n",
      "TRAIN Dataset loaded. Size: 35762\n",
      "\n",
      "\n",
      "**********VALIDATION DATASET *********\n",
      "Validation/Train ratio: 0.1\n",
      "Samples filtered? NO\n",
      "Samples evenly spaced? False\n",
      "path: DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\n",
      "loading dataset. Ready in a minute!\n",
      "VALIDATION Dataset loaded. Size: 3974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IRREGULAR firstdv_net\n",
    "dataset_path=\"DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\"\n",
    "train_dataset = IrregularDataset(ManeuverDetectionDataset(dataset_path, dataset_type=\"TRAIN\"))\n",
    "valid_dataset = IrregularDataset(ManeuverDetectionDataset(dataset_path, dataset_type=\"VALIDATION\"))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, drop_last=True, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(model=conv_net_1000, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:41<00:00, 13.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48627296, 0.48849425, 0.48689064]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(train_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_valid, pred_valid = trainer.predict(valid_loader, return_true=True)\n",
    "true_train, pred_train = trainer.predict(train_loader, return_true=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8291)\n",
      "tensor(0.8280)\n"
     ]
    }
   ],
   "source": [
    "print(torch.count_nonzero(torch.argmax(pred_valid[0], dim=1) == true_valid[0])/true_valid[0].shape[0])\n",
    "print(torch.count_nonzero(torch.argmax(pred_train[0], dim=1) == true_train[0])/true_train[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17830,    20],\n",
       "       [ 6132, 11778]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true, y_pred = true_train[0].cpu().numpy(), torch.argmax(pred_train[0], dim=1).cpu().numpy()\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1988,    5],\n",
       "       [ 673, 1302]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = true_valid[0].cpu().numpy(), torch.argmax(pred_valid[0], dim=1).cpu().numpy()\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Step - First solution\n",
    "\n",
    "Now that we have the problematric ones, we can try to determine both the dV and the time of the maneuver.\n",
    "How do we do ?\n",
    "\n",
    "We use a simple linear model on the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**********TRAIN DATASET *********\n",
      "Validation/Train ratio: 0.1\n",
      "Samples filtered? MANEUVER_ONLY\n",
      "Samples evenly spaced? False\n",
      "path: DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\n",
      "loading dataset. Ready in a minute!\n",
      "TRAIN Dataset loaded. Size: 17902\n",
      "\n",
      "\n",
      "**********VALIDATION DATASET *********\n",
      "Validation/Train ratio: 0.1\n",
      "Samples filtered? MANEUVER_ONLY\n",
      "Samples evenly spaced? False\n",
      "path: DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\n",
      "loading dataset. Ready in a minute!\n",
      "VALIDATION Dataset loaded. Size: 1989\n"
     ]
    }
   ],
   "source": [
    "dataset_path=\"DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\"\n",
    "\n",
    "train_dataset_man_only = IrregularDataset(ManeuverDetectionDataset(dataset_path, dataset_type=\"TRAIN\", filter_samples='MANEUVER_ONLY'))\n",
    "valid_dataset_man_only = IrregularDataset(ManeuverDetectionDataset(dataset_path, dataset_type=\"VALIDATION\", filter_samples='MANEUVER_ONLY'))\n",
    "\n",
    "train_loader_man_only = DataLoader(train_dataset, batch_size=8, drop_last=True, shuffle=True)\n",
    "valid_loader_man_only = DataLoader(valid_dataset, batch_size=8, drop_last=True, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManeuverTimeHead(torch.nn.Module):\n",
    "    def __init__(self, in_features) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_features, out_features=5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(5, out_features=1)\n",
    "        self.output_fn = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        x = self.linear1(embedding)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return torch.squeeze(self.output_fn(x))\n",
    "\n",
    "class DeltaVelocityHead(torch.nn.Module):\n",
    "    def __init__(self, in_features) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_features, out_features=5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(5, out_features=1)\n",
    "        self.output_fn = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        x = self.linear1(embedding)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return torch.squeeze(x) # Dv max is like 1.5 in absolute value\n",
    "    \n",
    "class Wrapper(torch.nn.Module):\n",
    "    def __init__(self, convnet, model_to_train) -> None:\n",
    "        super().__init__()\n",
    "        self.convnet = convnet\n",
    "        self.model_to_train = model_to_train\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c, embedding = self.convnet.predict(x, return_embedding=True) # NOTE : we suppose we only send in data with manuver in it\n",
    "        output = self.model_to_train(embedding) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "maneuver_time_net = ManeuverTimeHead(linear_kwargs_1000['out_features'])\n",
    "dv_net = DeltaVelocityHead(linear_kwargs_1000['out_features'])\n",
    "\n",
    "# freeze network\n",
    "for param in conv_net_1000.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "time_net_wrapper = Wrapper(conv_net_1000, maneuver_time_net)\n",
    "dv_net_wrapper = Wrapper(conv_net_1000, dv_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_trainer = TorchTrainer(model=time_net_wrapper, lr=5e-4, index_y=2, loss_function='L1Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:15<00:00,  7.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21996212922206332,\n",
       " 0.18889705005134175,\n",
       " 0.18826138612014515,\n",
       " 0.18815250698006686,\n",
       " 0.1875954427024282,\n",
       " 0.1873557610303804,\n",
       " 0.18718162148216413,\n",
       " 0.18668309471590014,\n",
       " 0.1864413131724091,\n",
       " 0.18525062181217208]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_trainer.train(train_loader_man_only, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_trainer = TorchTrainer(model=dv_net_wrapper, lr=2e-4, index_y=1, loss_function='L1Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:24<00:56,  8.12s/it]"
     ]
    }
   ],
   "source": [
    "dv_trainer.train(train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_time, pred_time = time_trainer.predict(valid_loader_man_only, return_true=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dv, pred_dv = dv_trainer.predict(valid_loader_man_only, return_true=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2270, dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_loss(true_time[0], pred_time[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4851, dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_loss(true_dv[0], pred_dv[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class InferenceWrapper(torch.nn.Module):\n",
    "    def __init__(self, convnet, dv_net, time_net) -> None:\n",
    "        super().__init__()\n",
    "        self.convnet = convnet\n",
    "        self.dv_net = dv_net\n",
    "        self.time_net = time_net\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c, embedding = self.convnet(x)\n",
    "        dv = self.dv_net(embedding) \n",
    "        time = self.time_net(embedding)\n",
    "        return (c, dv, time), embedding\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        self.eval()\n",
    "        cc_list = []\n",
    "        time_list = []\n",
    "        dv_list = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in dataloader:\n",
    "                c, embedding = self.convnet.predict(x, return_embedding=True)\n",
    "                cc = torch.argmax(c, dim=-1)\n",
    "                # cache = cc == 1\n",
    "                # dv = torch.zeros(cc.shape)\n",
    "                # time = torch.zeros(cc.shape)\n",
    "                dv = self.dv_net(embedding)\n",
    "                time = self.time_net(embedding)\n",
    "                cc_list.append(cc.cpu().numpy())\n",
    "                time_list.append(time.cpu().numpy())\n",
    "                dv_list.append(dv.cpu().numpy())\n",
    "        return (np.concatenate(cc_list),\n",
    "                np.array(dv_list),\n",
    "                np.array(time_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**********TEST DATASET *********\n",
      "Validation/Train ratio: 0.1\n",
      "Samples filtered? NO\n",
      "Samples evenly spaced? False\n",
      "path: DATA/TEST_FILE_PUBLIC.json\n",
      "loading dataset. Ready in a minute!\n",
      "TEST Dataset loaded. Size: 1559\n",
      "\n",
      "\n",
      "**********TEST DATASET *********\n",
      "Validation/Train ratio: 0.1\n",
      "Samples filtered? NO\n",
      "Samples evenly spaced? False\n",
      "path: DATA/TRAIN_1_IRREGULAR_STEPS_V2.json\n",
      "TEST Dataset loaded. Size: 1559\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path=\"DATA/TEST_FILE_PUBLIC.json\"\n",
    "test_dataset= ManeuverDetectionDataset(test_dataset_path, dataset_type=\"TEST\")\n",
    "test_dataset_irr = IrregularDataset(ManeuverDetectionDataset(dataset_path, dataset_type=\"TEST\", imported_dataset=test_dataset.dataset))\n",
    "test_loader = DataLoader(test_dataset_irr, batch_size=1, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze network\n",
    "\n",
    "inference_wrapper = InferenceWrapper(\n",
    "        convnet=conv_net_1000,\n",
    "        dv_net=dv_net,\n",
    "        time_net=maneuver_time_net\n",
    ")\n",
    "for param in inference_wrapper.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference_wrapper.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1559, 3)\n"
     ]
    }
   ],
   "source": [
    "pred = np.stack(preds, axis=1) \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2099672 , 0.20466721, 0.03757284, ..., 0.03443215, 0.02545385,\n",
       "       0.02452524])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:,2]=48*3600*pred[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SubmissionGenerator import create_submission\n",
    "import numpy as np\n",
    "# pred[:,1]=0.01*np.ones((len(test_dataset))) #dv\n",
    "create_submission(pred,\"DATA/prediction\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second step - Second Solution : for those we detected an anomaly for\n",
    "We split them in several subseries (sliding windows) and we have to find where the anomaly start occuring. \n",
    "For each small window, we determine a new score of anomaly. We can refine as many time as required.\n",
    "\n",
    "May be now we can try predicting the time of the anomaly occuring. I am not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManeuverDetectionDataset import ManeuverDetectionDataset, ManeuverDetectionSlidingWindowDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "evenly_spaced_dataset_path=\"DATA/TRAIN_1_EVENLY_SPACED_V2.json\"\n",
    "evenly_spaced_dataset= ManeuverDetectionDataset(evenly_spaced_dataset_path, fixed_step=True) # window_size=30)\n",
    "evenly_spaced_dataset_sliding_window = ManeuverDetectionSlidingWindowDataset(evenly_spaced_dataset, window_size=433)\n",
    "# feature,is_maneuver,maneuver_dv,maneuver_time =next(iter(evenly_spaced_loader))\n",
    "# print(f\"features shape (batch size * nb of meas * nb of feature):{feature.shape}\\nis maneuver: {is_maneuver.item()}\\ndv (m/s): {maneuver_dv.item()}\\nmaneuver date (seconds from the observation start): {maneuver_time.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evenly_spaced_loader = DataLoader(evenly_spaced_dataset_sliding_window, batch_size=32, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(evenly_spaced_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evenly_spaced_dataset_valid = ManeuverDetectionDataset(evenly_spaced_dataset_path, dataset_type='VALIDATION', fixed_step=True)\n",
    "valid_set = ManeuverDetectionSlidingWindowDataset(evenly_spaced_dataset_valid, window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(evenly_spaced_dataset_sliding_window, batch_size=1, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, pred = trainer.predict(valid_loader, return_true=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.count_nonzero(torch.argmax(pred[0], dim=1) == true[0])/true[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_true, y_pred = true[0].cpu().numpy(), torch.argmax(pred[0], dim=1).cpu().numpy()\n",
    "metrics.confusion_matrix(y_true, y_pred) # problem with those definitely - class are completly UNBALANCED. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_kwargs_list_30 = [\n",
    "    { # layer 1\n",
    "        'conv_kwargs': {\n",
    "            'in_channels': 2,\n",
    "            'out_channels': 4,\n",
    "            'kernel_size': 3,\n",
    "            'stride': 1,\n",
    "            'padding': 0,\n",
    "            'dilation': 1,\n",
    "            'groups': 1,\n",
    "            'bias': True,\n",
    "            'padding_mode': 'zeros'\n",
    "        },\n",
    "        'pool_kwargs': {\n",
    "            'kernel_size': 3,\n",
    "            'stride': None,\n",
    "            'padding': 0,\n",
    "            'dilation': 1\n",
    "        },\n",
    "        'dropout_rate': 0\n",
    "    },\n",
    "    { # layer 2\n",
    "        'conv_kwargs': {\n",
    "            'in_channels': 4,\n",
    "            'out_channels': 4,\n",
    "            'kernel_size': 3,\n",
    "            'stride': 1,\n",
    "            'padding': 0,\n",
    "            'dilation': 1,\n",
    "            'groups': 1,\n",
    "            'bias': True,\n",
    "            'padding_mode': 'zeros'\n",
    "        },\n",
    "        'pool_kwargs': {\n",
    "            'kernel_size': 3,\n",
    "            'stride': None,\n",
    "            'padding': 0,\n",
    "            'dilation': 1\n",
    "        },\n",
    "        'dropout_rate': 0\n",
    "    }\n",
    "]\n",
    "linear_kwargs_30 = {\n",
    "    'in_features': 8,\n",
    "    'out_features': 10 # size of the projection space (dimension reduction)\n",
    "}\n",
    "conv_net_30 = Cnn1d(block_kwargs_list_30, linear_kwargs_30).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19916/536388 * 100 # 3.72% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = torch.nn.CrossEntropyLoss(weight=torch.tensor([0.05, 0.95]))\n",
    "mae_loss_1 = torch.nn.L1Loss()\n",
    "mae_loss_2 = torch.nn.L1Loss()\n",
    "def total_loss_function(pred, true, alpha=0.5, beta=0.1, gamma=0.4):\n",
    "    c_true, dv_true, date_true = true\n",
    "    c, dv, date = pred\n",
    "    return alpha * cross_entropy_loss(c, c_true) + beta * mae_loss_1(dv, dv_true) + gamma * mae_loss_2(date_true, date)\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98e39df5b3c61a6cccd34f8912856fa306a2dda7557d908626d35ee2df110a90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
